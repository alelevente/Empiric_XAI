{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0050f2ee-edc3-4298-a23b-8ac4848da1d6",
   "metadata": {},
   "source": [
    "# **Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482c4d0f-c20f-4a31-a3a1-ca9835fe3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/madbiker/miniconda3/envs/xai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0cc34-ca3f-4c57-8a84-4d6555636bc4",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3717dc-a752-45ce-b8da-fbf8c3755d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"../01_data/adult_reconstruction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d4ab02-8ab8-44b1-a8d7-164e7b57a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv(DATA_SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4763c17-27cf-4bcd-8378-583504d3f484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>49100</td>\n",
       "      <td>Tech-support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>11500</td>\n",
       "      <td>Craft-repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>2600</td>\n",
       "      <td>Other-service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>38997</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>?</td>\n",
       "      <td>41400</td>\n",
       "      <td>Exec-managerial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hours-per-week  age  capital-gain  capital-loss workclass     education  \\\n",
       "0              20   40             0             0   Private     Bachelors   \n",
       "1              40   21             0             0   Private  Some-college   \n",
       "2              10   17             0             0   Private          11th   \n",
       "3              50   51             0             0   Private       HS-grad   \n",
       "4              38   28             0             0   Private     Bachelors   \n",
       "\n",
       "   education-num      marital-status   relationship                race  \\\n",
       "0             13  Married-civ-spouse           Wife               White   \n",
       "1             10            Divorced      Own-child               White   \n",
       "2              7       Never-married      Own-child               White   \n",
       "3              9  Married-civ-spouse        Husband  Asian-Pac-Islander   \n",
       "4             13       Never-married  Not-in-family               White   \n",
       "\n",
       "   gender native-country  income       occupation  \n",
       "0  Female  United-States   49100     Tech-support  \n",
       "1    Male  United-States   11500     Craft-repair  \n",
       "2    Male  United-States    2600    Other-service  \n",
       "3    Male       Cambodia   38997            Sales  \n",
       "4    Male              ?   41400  Exec-managerial  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1bb892-140f-476d-a6e2-e5c49e205ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Private', '?', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov',\n",
       "       'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data[\"workclass\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cf1cea1-4201-4a07-b753-641605ec6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = census_data.drop(columns=[\"education\", \"income\"]) #education: redundandt, income: label\n",
    "\n",
    "#categorical encodings:\n",
    "categorical = [\"workclass\", \"marital-status\", \"relationship\", \"race\", \"gender\", \"native-country\", \"occupation\"]\n",
    "code_dictionary = {} #original values -> codes\n",
    "for c in categorical:\n",
    "    values = []\n",
    "    #updating the code_dictionary:\n",
    "    codes = census_data[c].unique()\n",
    "    code_dictionary[c] = {}\n",
    "    for i,code in enumerate(codes):\n",
    "        code_dictionary[c][code] = i\n",
    "    for _,r in x.iterrows():\n",
    "        values.append(code_dictionary[c][r[c]])\n",
    "    x[c] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175da531-967d-4881-9fca-126bd6687c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49526</th>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49527</th>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>3137</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49528</th>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49529</th>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49530</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>3464</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49531 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hours-per-week  age  capital-gain  capital-loss  workclass  \\\n",
       "0                  20   40             0             0          0   \n",
       "1                  40   21             0             0          0   \n",
       "2                  10   17             0             0          0   \n",
       "3                  50   51             0             0          0   \n",
       "4                  38   28             0             0          0   \n",
       "...               ...  ...           ...           ...        ...   \n",
       "49526              65   35             0             0          0   \n",
       "49527              77   37          3137             0          2   \n",
       "49528              55   24             0             0          0   \n",
       "49529              40   24             0             0          0   \n",
       "49530              20   39          3464             0          6   \n",
       "\n",
       "       education-num  marital-status  relationship  race  gender  \\\n",
       "0                 13               0             0     0       0   \n",
       "1                 10               1             1     0       1   \n",
       "2                  7               2             1     0       1   \n",
       "3                  9               0             2     1       1   \n",
       "4                 13               2             3     0       1   \n",
       "...              ...             ...           ...   ...     ...   \n",
       "49526             13               0             2     0       1   \n",
       "49527             13               0             2     1       1   \n",
       "49528             11               2             3     0       1   \n",
       "49529             10               2             3     0       0   \n",
       "49530              9               0             0     1       0   \n",
       "\n",
       "       native-country  occupation  \n",
       "0                   0           0  \n",
       "1                   0           1  \n",
       "2                   0           2  \n",
       "3                   1           3  \n",
       "4                   2           4  \n",
       "...               ...         ...  \n",
       "49526              36          10  \n",
       "49527              20           3  \n",
       "49528               0           3  \n",
       "49529               0           9  \n",
       "49530               0           9  \n",
       "\n",
       "[49531 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0189cccd-c889-4732-8062-b0073972f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = census_data[\"income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863e64b-97cf-4a15-83e0-d34e5014d4bd",
   "metadata": {},
   "source": [
    "## **Training a neural network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba26391-d84e-4bc0-9132-a8df6dc86023",
   "metadata": {},
   "source": [
    "### **Definition of the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a317a0f2-21b9-4108-913f-e55ee31d0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(len(x.columns))),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(200, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(500, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(200, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b45f31c-e1d7-4c71-9262-2ec29646d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39624 samples, validate on 9907 samples\n",
      "Epoch 1/1000\n",
      "39624/39624 [==============================] - 1s 26us/sample - loss: 1830163789.1670 - val_loss: 1931148675.4238\n",
      "Epoch 2/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1823452514.5391 - val_loss: 1924280750.0991\n",
      "Epoch 3/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1816814364.6081 - val_loss: 1917449339.7105\n",
      "Epoch 4/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1810214267.4000 - val_loss: 1910676137.9388\n",
      "Epoch 5/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1803658145.5183 - val_loss: 1903918752.0161\n",
      "Epoch 6/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1797131720.3343 - val_loss: 1897204696.3351\n",
      "Epoch 7/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1790634985.3358 - val_loss: 1890537521.0578\n",
      "Epoch 8/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1784173296.0808 - val_loss: 1883877681.3938\n",
      "Epoch 9/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1777737558.5738 - val_loss: 1877248468.9113\n",
      "Epoch 10/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1771327342.8403 - val_loss: 1870662573.9053\n",
      "Epoch 11/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1764951246.3557 - val_loss: 1864096099.7953\n",
      "Epoch 12/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1758598699.1577 - val_loss: 1857561428.0069\n",
      "Epoch 13/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1752276739.2304 - val_loss: 1851056446.7532\n",
      "Epoch 14/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1745983772.7632 - val_loss: 1844573164.9944\n",
      "Epoch 15/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1739718379.5582 - val_loss: 1838124327.1222\n",
      "Epoch 16/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1733483120.5201 - val_loss: 1831696123.8009\n",
      "Epoch 17/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1727271808.2067 - val_loss: 1825302541.3853\n",
      "Epoch 18/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1721088991.7480 - val_loss: 1818940725.1406\n",
      "Epoch 19/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1714940039.8046 - val_loss: 1812578595.9439\n",
      "Epoch 20/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1708804259.6374 - val_loss: 1806278850.0608\n",
      "Epoch 21/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1702704030.3654 - val_loss: 1799989081.7047\n",
      "Epoch 22/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1696623291.0769 - val_loss: 1793736321.6538\n",
      "Epoch 23/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1690575886.8338 - val_loss: 1787490187.4860\n",
      "Epoch 24/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1684553725.9843 - val_loss: 1781269806.7451\n",
      "Epoch 25/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1678548646.5318 - val_loss: 1775103845.8367\n",
      "Epoch 26/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1672583087.1633 - val_loss: 1768941213.7551\n",
      "Epoch 27/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1666639773.8744 - val_loss: 1762801558.0676\n",
      "Epoch 28/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1660713926.8355 - val_loss: 1756709197.5080\n",
      "Epoch 29/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1654821256.8900 - val_loss: 1750625343.0374\n",
      "Epoch 30/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1648947869.3834 - val_loss: 1744568462.2122\n",
      "Epoch 31/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1643101976.6541 - val_loss: 1738528984.1542\n",
      "Epoch 32/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1637275803.4193 - val_loss: 1732533395.3802\n",
      "Epoch 33/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 1631476394.1757 - val_loss: 1726559867.0387\n",
      "Epoch 34/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 1625708860.0590 - val_loss: 1720581093.5654\n",
      "Epoch 35/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1619954654.9727 - val_loss: 1714657761.4826\n",
      "Epoch 36/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1614235513.2292 - val_loss: 1708749444.7934\n",
      "Epoch 37/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1608534061.8453 - val_loss: 1702873409.9574\n",
      "Epoch 38/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1602859192.1825 - val_loss: 1697014738.2885\n",
      "Epoch 39/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1597205898.0271 - val_loss: 1691173671.1610\n",
      "Epoch 40/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1591575723.3903 - val_loss: 1685364092.0077\n",
      "Epoch 41/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1585971692.9796 - val_loss: 1679576157.4515\n",
      "Epoch 42/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1580388894.1587 - val_loss: 1673815328.0678\n",
      "Epoch 43/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1574829911.2457 - val_loss: 1668076051.6516\n",
      "Epoch 44/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1569294589.7775 - val_loss: 1662363450.0761\n",
      "Epoch 45/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1563779559.3459 - val_loss: 1656663272.6791\n",
      "Epoch 46/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1558291092.0541 - val_loss: 1650975089.9429\n",
      "Epoch 47/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1552820000.7688 - val_loss: 1645330500.2055\n",
      "Epoch 48/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1547375857.0628 - val_loss: 1639718821.3134\n",
      "Epoch 49/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1541956376.9643 - val_loss: 1634106269.8972\n",
      "Epoch 50/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1536554462.0941 - val_loss: 1628527032.3319\n",
      "Epoch 51/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1531179040.0711 - val_loss: 1622963110.1274\n",
      "Epoch 52/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1525826477.9487 - val_loss: 1617420802.9458\n",
      "Epoch 53/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1520490095.4605 - val_loss: 1611919347.1574\n",
      "Epoch 54/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1515184361.4650 - val_loss: 1606424968.6565\n",
      "Epoch 55/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1509891954.3033 - val_loss: 1600963475.5094\n",
      "Epoch 56/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 1504629469.3188 - val_loss: 1595505717.0889\n",
      "Epoch 57/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1499385106.6069 - val_loss: 1590074022.3987\n",
      "Epoch 58/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1494161085.7646 - val_loss: 1584678541.5403\n",
      "Epoch 59/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1488962202.2564 - val_loss: 1579295418.3345\n",
      "Epoch 60/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1483781780.9328 - val_loss: 1573940201.9453\n",
      "Epoch 61/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1478620593.2308 - val_loss: 1568611717.2327\n",
      "Epoch 62/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1473487941.9051 - val_loss: 1563275017.2121\n",
      "Epoch 63/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1468364826.7474 - val_loss: 1557984241.1806\n",
      "Epoch 64/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1463273779.1173 - val_loss: 1552705977.7919\n",
      "Epoch 65/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1458199135.6705 - val_loss: 1547453232.9674\n",
      "Epoch 66/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1453148062.2104 - val_loss: 1542224383.7158\n",
      "Epoch 67/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1448118675.0979 - val_loss: 1536999211.9027\n",
      "Epoch 68/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1443103907.7149 - val_loss: 1531820441.4398\n",
      "Epoch 69/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1438117230.5819 - val_loss: 1526653167.8498\n",
      "Epoch 70/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1433148629.3333 - val_loss: 1521503560.6888\n",
      "Epoch 71/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1428197978.5536 - val_loss: 1516373965.8439\n",
      "Epoch 72/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1423272829.5966 - val_loss: 1511255143.1675\n",
      "Epoch 73/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1418360567.5494 - val_loss: 1506184093.6259\n",
      "Epoch 74/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1413475982.0327 - val_loss: 1501115689.9647\n",
      "Epoch 75/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1408606563.8312 - val_loss: 1496065080.9391\n",
      "Epoch 76/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1403758608.7979 - val_loss: 1491038189.9764\n",
      "Epoch 77/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1398927113.7945 - val_loss: 1486030730.5816\n",
      "Epoch 78/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1394119253.7468 - val_loss: 1481050075.0871\n",
      "Epoch 79/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1389333182.2814 - val_loss: 1476074171.3423\n",
      "Epoch 80/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1384563849.1484 - val_loss: 1471122319.7497\n",
      "Epoch 81/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1379815365.4916 - val_loss: 1466201400.5386\n",
      "Epoch 82/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1375084417.8348 - val_loss: 1461301372.4340\n",
      "Epoch 83/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1370381818.5988 - val_loss: 1456400287.0859\n",
      "Epoch 84/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1365691645.7775 - val_loss: 1451537410.3256\n",
      "Epoch 85/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1361025717.7274 - val_loss: 1446694189.4273\n",
      "Epoch 86/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1356379466.4793 - val_loss: 1441860898.2772\n",
      "Epoch 87/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1351746455.6980 - val_loss: 1437074466.8844\n",
      "Epoch 88/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1347147531.4226 - val_loss: 1432267067.5878\n",
      "Epoch 89/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1342552256.2197 - val_loss: 1427511944.1397\n",
      "Epoch 90/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1337983496.6832 - val_loss: 1422764247.7795\n",
      "Epoch 91/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1333436404.5257 - val_loss: 1418030427.3584\n",
      "Epoch 92/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1328905634.8621 - val_loss: 1413330227.2284\n",
      "Epoch 93/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1324394929.3083 - val_loss: 1408650845.6195\n",
      "Epoch 94/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1319905839.5768 - val_loss: 1403982868.6593\n",
      "Epoch 95/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1315434718.4042 - val_loss: 1399320142.9034\n",
      "Epoch 96/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1310979139.3208 - val_loss: 1394684593.4454\n",
      "Epoch 97/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1306544401.5215 - val_loss: 1390077144.0767\n",
      "Epoch 98/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1302131902.0747 - val_loss: 1385489508.7643\n",
      "Epoch 99/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1297737844.6808 - val_loss: 1380913657.1394\n",
      "Epoch 100/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1293358127.3959 - val_loss: 1376364730.1795\n",
      "Epoch 101/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1289001556.2221 - val_loss: 1371827113.6158\n",
      "Epoch 102/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1284662141.5966 - val_loss: 1367309167.1909\n",
      "Epoch 103/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1280340729.6426 - val_loss: 1362814240.4038\n",
      "Epoch 104/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1276039999.8837 - val_loss: 1358341599.3895\n",
      "Epoch 105/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 1271759238.2023 - val_loss: 1353871507.0185\n",
      "Epoch 106/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 1267495399.2425 - val_loss: 1349428718.0539\n",
      "Epoch 107/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1263249390.7369 - val_loss: 1345010067.3286\n",
      "Epoch 108/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1259024705.7961 - val_loss: 1340607128.9617\n",
      "Epoch 109/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1254820304.8625 - val_loss: 1336226975.3701\n",
      "Epoch 110/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1250632301.0571 - val_loss: 1331870327.6407\n",
      "Epoch 111/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1246466611.8926 - val_loss: 1327523704.4417\n",
      "Epoch 112/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1242317271.9435 - val_loss: 1323194943.2183\n",
      "Epoch 113/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1238181677.5352 - val_loss: 1318893391.8466\n",
      "Epoch 114/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 1234070991.9063 - val_loss: 1314593209.1329\n",
      "Epoch 115/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 1229976277.9536 - val_loss: 1310321988.6577\n",
      "Epoch 116/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 1225897718.7999 - val_loss: 1306081214.3139\n",
      "Epoch 117/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1221844507.8845 - val_loss: 1301840671.4864\n",
      "Epoch 118/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 1217803818.3695 - val_loss: 1297628632.5935\n",
      "Epoch 119/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1213784721.1468 - val_loss: 1293428814.6450\n",
      "Epoch 120/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1209781780.5839 - val_loss: 1289251716.1732\n",
      "Epoch 121/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1205796839.0745 - val_loss: 1285101055.7804\n",
      "Epoch 122/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1201834120.9675 - val_loss: 1280956539.4521\n",
      "Epoch 123/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1197886778.5471 - val_loss: 1276836163.3528\n",
      "Epoch 124/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1193961128.9223 - val_loss: 1272735200.6299\n",
      "Epoch 125/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1190049433.9592 - val_loss: 1268658499.2623\n",
      "Epoch 126/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1186160724.9198 - val_loss: 1264574041.0457\n",
      "Epoch 127/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1182279348.8746 - val_loss: 1260527959.7537\n",
      "Epoch 128/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1178426754.6231 - val_loss: 1256490495.8062\n",
      "Epoch 129/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1174585789.0281 - val_loss: 1252483720.2947\n",
      "Epoch 130/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1170767731.4533 - val_loss: 1248492303.3233\n",
      "Epoch 131/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1166968344.9384 - val_loss: 1244505600.3359\n",
      "Epoch 132/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1163184938.6408 - val_loss: 1240554371.9406\n",
      "Epoch 133/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1159422333.9196 - val_loss: 1236624223.9451\n",
      "Epoch 134/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1155678847.7157 - val_loss: 1232706324.7756\n",
      "Epoch 135/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1151951155.7375 - val_loss: 1228796527.8369\n",
      "Epoch 136/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1148235785.2259 - val_loss: 1224927044.7998\n",
      "Epoch 137/1000\n",
      "39624/39624 [==============================] - 0s 13us/sample - loss: 1144550788.3804 - val_loss: 1221037579.8478\n",
      "Epoch 138/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1140869341.7969 - val_loss: 1217197182.9405\n",
      "Epoch 139/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1137213728.1357 - val_loss: 1213364056.9294\n",
      "Epoch 140/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1133578136.0339 - val_loss: 1209539694.4157\n",
      "Epoch 141/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1129954573.5675 - val_loss: 1205744595.3996\n",
      "Epoch 142/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1126351868.1752 - val_loss: 1201977784.7583\n",
      "Epoch 143/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1122771055.9128 - val_loss: 1198223388.8507\n",
      "Epoch 144/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1119203511.9758 - val_loss: 1194485573.1099\n",
      "Epoch 145/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1115661703.6366 - val_loss: 1190749288.7696\n",
      "Epoch 146/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1112125254.6029 - val_loss: 1187060937.8258\n",
      "Epoch 147/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1108614749.4997 - val_loss: 1183382941.0187\n",
      "Epoch 148/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1105125341.3705 - val_loss: 1179704052.9145\n",
      "Epoch 149/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1101643858.2322 - val_loss: 1176059507.2478\n",
      "Epoch 150/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1098185370.6828 - val_loss: 1172419723.4473\n",
      "Epoch 151/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1094741016.8738 - val_loss: 1168810221.3821\n",
      "Epoch 152/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1091318842.7410 - val_loss: 1165205623.9766\n",
      "Epoch 153/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1087912248.6606 - val_loss: 1161623518.7306\n",
      "Epoch 154/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1084516781.3156 - val_loss: 1158082782.5885\n",
      "Epoch 155/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1081154707.8861 - val_loss: 1154519489.4794\n",
      "Epoch 156/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1077799695.3636 - val_loss: 1150995185.0901\n",
      "Epoch 157/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1074463937.3697 - val_loss: 1147492127.8353\n",
      "Epoch 158/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1071146270.5851 - val_loss: 1143999130.1181\n",
      "Epoch 159/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1067845267.4210 - val_loss: 1140523177.4349\n",
      "Epoch 160/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 1064560183.4718 - val_loss: 1137076682.1746\n",
      "Epoch 161/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1061296787.4726 - val_loss: 1133637124.5996\n",
      "Epoch 162/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1058047450.4502 - val_loss: 1130221985.5020\n",
      "Epoch 163/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1054819090.6715 - val_loss: 1126814305.8056\n",
      "Epoch 164/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1051605702.1894 - val_loss: 1123420989.8359\n",
      "Epoch 165/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1048406207.5994 - val_loss: 1120065472.4974\n",
      "Epoch 166/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1045234321.6895 - val_loss: 1116700772.9581\n",
      "Epoch 167/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1042068820.0412 - val_loss: 1113385319.5034\n",
      "Epoch 168/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 1038933554.7943 - val_loss: 1110060503.0819\n",
      "Epoch 169/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1035803216.1777 - val_loss: 1106777318.7863\n",
      "Epoch 170/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1032699846.5383 - val_loss: 1103491507.8615\n",
      "Epoch 171/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1029605997.5998 - val_loss: 1100233035.6604\n",
      "Epoch 172/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1026533870.5043 - val_loss: 1096983415.9378\n",
      "Epoch 173/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1023477200.3844 - val_loss: 1093746684.3565\n",
      "Epoch 174/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1020436381.7840 - val_loss: 1090546752.3295\n",
      "Epoch 175/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1017416945.3471 - val_loss: 1087358168.4643\n",
      "Epoch 176/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1014415283.9701 - val_loss: 1084180057.1620\n",
      "Epoch 177/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1011426706.6974 - val_loss: 1081024720.6993\n",
      "Epoch 178/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 1008464485.7048 - val_loss: 1077870602.2457\n",
      "Epoch 179/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1005505593.2162 - val_loss: 1074764508.2499\n",
      "Epoch 180/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 1002575081.2324 - val_loss: 1071657848.0024\n",
      "Epoch 181/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 999655827.2142 - val_loss: 1068573880.5709\n",
      "Epoch 182/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 996757118.0876 - val_loss: 1065502824.5564\n",
      "Epoch 183/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 993876941.3996 - val_loss: 1062441990.9510\n",
      "Epoch 184/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 991007837.4351 - val_loss: 1059404534.3228\n",
      "Epoch 185/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 988157818.5859 - val_loss: 1056393547.0532\n",
      "Epoch 186/1000\n",
      "39624/39624 [==============================] - 0s 13us/sample - loss: 985330893.0507 - val_loss: 1053379665.2355\n",
      "Epoch 187/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 982512162.3323 - val_loss: 1050403997.2771\n",
      "Epoch 188/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 979720412.7632 - val_loss: 1047430615.5147\n",
      "Epoch 189/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 976933138.4777 - val_loss: 1044502819.3496\n",
      "Epoch 190/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 974174233.0030 - val_loss: 1041564781.6792\n",
      "Epoch 191/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 971428106.5310 - val_loss: 1038646706.0785\n",
      "Epoch 192/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 968697846.0634 - val_loss: 1035751386.3313\n",
      "Epoch 193/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 965986033.0240 - val_loss: 1032863191.9992\n",
      "Epoch 194/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 963289994.6344 - val_loss: 1029995791.8724\n",
      "Epoch 195/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 960613781.6693 - val_loss: 1027154829.8246\n",
      "Epoch 196/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 957956574.8048 - val_loss: 1024327479.5631\n",
      "Epoch 197/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 955314486.1280 - val_loss: 1021520401.5068\n",
      "Epoch 198/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 952687152.6622 - val_loss: 1018725665.0045\n",
      "Epoch 199/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 950079889.0951 - val_loss: 1015942393.0231\n",
      "Epoch 200/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 947483048.5605 - val_loss: 1013195712.4328\n",
      "Epoch 201/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 944915644.4337 - val_loss: 1010427182.5319\n",
      "Epoch 202/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 942351780.1155 - val_loss: 1007711142.3858\n",
      "Epoch 203/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 939809588.1123 - val_loss: 1005013546.7657\n",
      "Epoch 204/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 937290467.7020 - val_loss: 1002310816.6686\n",
      "Epoch 205/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 934781761.0466 - val_loss: 999637156.0537\n",
      "Epoch 206/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 932292800.9950 - val_loss: 996982907.3294\n",
      "Epoch 207/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 929822616.3182 - val_loss: 994342516.6238\n",
      "Epoch 208/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 927362859.1189 - val_loss: 991726592.3230\n",
      "Epoch 209/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 924927266.4099 - val_loss: 989104881.6005\n",
      "Epoch 210/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 922499470.6788 - val_loss: 986517578.1617\n",
      "Epoch 211/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 920091662.5496 - val_loss: 983946664.3109\n",
      "Epoch 212/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 917702033.3664 - val_loss: 981388798.4367\n",
      "Epoch 213/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 915326105.2615 - val_loss: 978850944.4199\n",
      "Epoch 214/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 912968035.0042 - val_loss: 976332243.8970\n",
      "Epoch 215/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 910628251.3547 - val_loss: 973831123.0831\n",
      "Epoch 216/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 908310910.0489 - val_loss: 971325219.7759\n",
      "Epoch 217/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 905997257.6265 - val_loss: 968867912.2172\n",
      "Epoch 218/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 903711114.5698 - val_loss: 966416456.0170\n",
      "Epoch 219/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 901440576.8787 - val_loss: 963966587.3875\n",
      "Epoch 220/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 899179110.6222 - val_loss: 961549373.2868\n",
      "Epoch 221/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 896936176.1971 - val_loss: 959142363.7525\n",
      "Epoch 222/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 894713422.9889 - val_loss: 956744438.0063\n",
      "Epoch 223/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 892508119.3362 - val_loss: 954366236.1918\n",
      "Epoch 224/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 890311605.5724 - val_loss: 952026535.9750\n",
      "Epoch 225/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 888141556.6550 - val_loss: 949680122.5219\n",
      "Epoch 226/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 885980939.5647 - val_loss: 947352017.5133\n",
      "Epoch 227/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 883836977.3471 - val_loss: 945048815.5526\n",
      "Epoch 228/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 881713587.1819 - val_loss: 942753851.4586\n",
      "Epoch 229/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 879601165.8518 - val_loss: 940480396.1256\n",
      "Epoch 230/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 877509837.7226 - val_loss: 938232071.0092\n",
      "Epoch 231/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 875435760.7914 - val_loss: 935985998.1928\n",
      "Epoch 232/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 873374158.2136 - val_loss: 933765178.0955\n",
      "Epoch 233/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 871329028.9489 - val_loss: 931573181.2609\n",
      "Epoch 234/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 869308923.9039 - val_loss: 929363983.4719\n",
      "Epoch 235/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 867292105.0063 - val_loss: 927206244.0989\n",
      "Epoch 236/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 865302048.9626 - val_loss: 925039718.1920\n",
      "Epoch 237/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 863320342.8839 - val_loss: 922905684.5947\n",
      "Epoch 238/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 861358803.7052 - val_loss: 920788214.6200\n",
      "Epoch 239/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 859415327.1795 - val_loss: 918667072.4522\n",
      "Epoch 240/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 857479698.7490 - val_loss: 916579457.8476\n",
      "Epoch 241/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 855567496.8641 - val_loss: 914497959.9168\n",
      "Epoch 242/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 853665647.1375 - val_loss: 912437730.8198\n",
      "Epoch 243/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 851784326.9001 - val_loss: 910385464.0541\n",
      "Epoch 244/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 849916302.7175 - val_loss: 908365205.8674\n",
      "Epoch 245/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 848071968.6913 - val_loss: 906340816.1308\n",
      "Epoch 246/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 846235544.7317 - val_loss: 904355485.9231\n",
      "Epoch 247/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 844415048.1276 - val_loss: 902383243.8349\n",
      "Epoch 248/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 842613717.3333 - val_loss: 900409889.9025\n",
      "Epoch 249/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 840826823.4815 - val_loss: 898453492.8887\n",
      "Epoch 250/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 839051169.7638 - val_loss: 896540904.3238\n",
      "Epoch 251/1000\n",
      "39624/39624 [==============================] - 1s 16us/sample - loss: 837299427.0430 - val_loss: 894626847.9192\n",
      "Epoch 252/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 835561293.5417 - val_loss: 892723535.6399\n",
      "Epoch 253/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 833837906.6198 - val_loss: 890840003.5272\n",
      "Epoch 254/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 832128618.6150 - val_loss: 888975688.1785\n",
      "Epoch 255/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 830438415.9580 - val_loss: 887112550.9995\n",
      "Epoch 256/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 828757801.5683 - val_loss: 885284271.8240\n",
      "Epoch 257/1000\n",
      "39624/39624 [==============================] - 1s 19us/sample - loss: 827098777.5587 - val_loss: 883463100.3436\n",
      "Epoch 258/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 825450655.8902 - val_loss: 881667962.3668\n",
      "Epoch 259/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 823825610.6473 - val_loss: 879867862.2550\n",
      "Epoch 260/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 822207273.9818 - val_loss: 878098473.7709\n",
      "Epoch 261/1000\n",
      "39624/39624 [==============================] - 0s 13us/sample - loss: 820609932.1333 - val_loss: 876342316.4453\n",
      "Epoch 262/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 819023224.4022 - val_loss: 874611403.5183\n",
      "Epoch 263/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 817461510.2281 - val_loss: 872867767.3241\n",
      "Epoch 264/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 815904230.2217 - val_loss: 871166113.9606\n",
      "Epoch 265/1000\n",
      "39624/39624 [==============================] - 1s 16us/sample - loss: 814365744.5072 - val_loss: 869473113.2395\n",
      "Epoch 266/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 812847815.2231 - val_loss: 867785799.0221\n",
      "Epoch 267/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 811342167.4525 - val_loss: 866124819.3156\n",
      "Epoch 268/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 809853925.4464 - val_loss: 864483986.1141\n",
      "Epoch 269/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 808378833.7541 - val_loss: 862857370.1375\n",
      "Epoch 270/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 806921921.1888 - val_loss: 861229421.4919\n",
      "Epoch 271/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 805474156.6178 - val_loss: 859640975.8595\n",
      "Epoch 272/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 804046590.4365 - val_loss: 858060337.2387\n",
      "Epoch 273/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 802636288.1163 - val_loss: 856486486.5974\n",
      "Epoch 274/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 801235385.3584 - val_loss: 854939192.8293\n",
      "Epoch 275/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 799850825.3810 - val_loss: 853404427.7703\n",
      "Epoch 276/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 798481786.4567 - val_loss: 851887475.1315\n",
      "Epoch 277/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 797128561.8768 - val_loss: 850371777.5117\n",
      "Epoch 278/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 795788936.8124 - val_loss: 848870099.3027\n",
      "Epoch 279/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 794457769.2582 - val_loss: 847405296.5798\n",
      "Epoch 280/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 793152917.1395 - val_loss: 845935985.3873\n",
      "Epoch 281/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 791857775.6285 - val_loss: 844476293.1551\n",
      "Epoch 282/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 790578221.9100 - val_loss: 843043194.8449\n",
      "Epoch 283/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 789312119.6527 - val_loss: 841634827.4408\n",
      "Epoch 284/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 788063603.3240 - val_loss: 840234812.9508\n",
      "Epoch 285/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 786827478.5996 - val_loss: 838847049.5028\n",
      "Epoch 286/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 785604044.1979 - val_loss: 837476614.7379\n",
      "Epoch 287/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 784395577.6685 - val_loss: 836118113.6893\n",
      "Epoch 288/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 783203369.8268 - val_loss: 834770021.8302\n",
      "Epoch 289/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 782022827.3903 - val_loss: 833441346.5647\n",
      "Epoch 290/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 780858875.1674 - val_loss: 832124469.6510\n",
      "Epoch 291/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 779706398.4559 - val_loss: 830829781.9836\n",
      "Epoch 292/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 778573965.6063 - val_loss: 829536565.3021\n",
      "Epoch 293/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 777450821.7501 - val_loss: 828272175.7723\n",
      "Epoch 294/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 776343114.1563 - val_loss: 827020793.5399\n",
      "Epoch 295/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 775253582.8338 - val_loss: 825778125.2173\n",
      "Epoch 296/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 774172929.3826 - val_loss: 824553655.1109\n",
      "Epoch 297/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 773110297.6103 - val_loss: 823334627.7501\n",
      "Epoch 298/1000\n",
      "39624/39624 [==============================] - 0s 10us/sample - loss: 772058215.3846 - val_loss: 822138936.7583\n",
      "Epoch 299/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 771023702.1732 - val_loss: 820953358.0055\n",
      "Epoch 300/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 770002576.0614 - val_loss: 819783115.6734\n",
      "Epoch 301/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 768997690.3921 - val_loss: 818621943.3112\n",
      "Epoch 302/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 767999745.1242 - val_loss: 817494100.0650\n",
      "Epoch 303/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 767020020.1381 - val_loss: 816369708.0254\n",
      "Epoch 304/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 766055821.0119 - val_loss: 815257217.1951\n",
      "Epoch 305/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 765100565.8243 - val_loss: 814164672.7881\n",
      "Epoch 306/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 764167171.7860 - val_loss: 813064860.9605\n",
      "Epoch 307/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 763233959.8369 - val_loss: 812008240.4635\n",
      "Epoch 308/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 762325722.6441 - val_loss: 810949070.7161\n",
      "Epoch 309/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 761426478.8532 - val_loss: 809910764.3355\n",
      "Epoch 310/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 760548375.2845 - val_loss: 808868077.1107\n",
      "Epoch 311/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 759672507.3224 - val_loss: 807871600.5669\n",
      "Epoch 312/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 758817481.7299 - val_loss: 806869893.6590\n",
      "Epoch 313/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 757970528.8076 - val_loss: 805898538.2231\n",
      "Epoch 314/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 757142212.1478 - val_loss: 804918820.4025\n",
      "Epoch 315/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 756323506.2386 - val_loss: 803960813.7567\n",
      "Epoch 316/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 755518400.1163 - val_loss: 803014561.7604\n",
      "Epoch 317/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 754724952.6412 - val_loss: 802082321.8686\n",
      "Epoch 318/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 753945363.7569 - val_loss: 801163638.8138\n",
      "Epoch 319/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 753176683.1835 - val_loss: 800260965.1261\n",
      "Epoch 320/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 752422304.2261 - val_loss: 799373657.7693\n",
      "Epoch 321/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 751681617.6895 - val_loss: 798486069.5411\n",
      "Epoch 322/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 750954422.7870 - val_loss: 797611808.8560\n",
      "Epoch 323/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 750234725.9503 - val_loss: 796769067.6314\n",
      "Epoch 324/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 749531974.3186 - val_loss: 795924466.0656\n",
      "Epoch 325/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 748838262.4898 - val_loss: 795093041.6522\n",
      "Epoch 326/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 748157073.3018 - val_loss: 794282558.9922\n",
      "Epoch 327/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 747492182.5738 - val_loss: 793478357.1374\n",
      "Epoch 328/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 746834910.5980 - val_loss: 792687870.6757\n",
      "Epoch 329/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 746192379.8522 - val_loss: 791916413.4935\n",
      "Epoch 330/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 745565421.4706 - val_loss: 791139784.6307\n",
      "Epoch 331/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 744941622.2960 - val_loss: 790404514.2190\n",
      "Epoch 332/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 744341914.1143 - val_loss: 789654475.6475\n",
      "Epoch 333/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 743742657.6281 - val_loss: 788934982.3696\n",
      "Epoch 334/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 743159694.6013 - val_loss: 788224903.5906\n",
      "Epoch 335/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 742585814.1732 - val_loss: 787526366.5239\n",
      "Epoch 336/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 742027249.8768 - val_loss: 786825633.3211\n",
      "Epoch 337/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 741475740.2722 - val_loss: 786149762.5259\n",
      "Epoch 338/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 740936373.8696 - val_loss: 785491190.4585\n",
      "Epoch 339/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 740414668.1849 - val_loss: 784814862.3285\n",
      "Epoch 340/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 739892623.8546 - val_loss: 784190010.2764\n",
      "Epoch 341/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 739391403.2998 - val_loss: 783559781.1455\n",
      "Epoch 342/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 738898620.0331 - val_loss: 782936891.4327\n",
      "Epoch 343/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 738416495.8482 - val_loss: 782330955.1178\n",
      "Epoch 344/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 737945692.0137 - val_loss: 781736787.4061\n",
      "Epoch 345/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 737486144.3747 - val_loss: 781146979.6790\n",
      "Epoch 346/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 737035889.7347 - val_loss: 780571985.9267\n",
      "Epoch 347/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 736594474.1498 - val_loss: 780015120.5959\n",
      "Epoch 348/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 736164444.6340 - val_loss: 779472392.2172\n",
      "Epoch 349/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 735748037.9826 - val_loss: 778923817.9388\n",
      "Epoch 350/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 735338794.6279 - val_loss: 778388687.9112\n",
      "Epoch 351/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 734936804.0767 - val_loss: 777879720.8083\n",
      "Epoch 352/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 734549994.5504 - val_loss: 777374206.4560\n",
      "Epoch 353/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 734175041.8736 - val_loss: 776873617.4939\n",
      "Epoch 354/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 733807132.1300 - val_loss: 776388351.8966\n",
      "Epoch 355/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 733446361.5974 - val_loss: 775924822.7782\n",
      "Epoch 356/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 733097780.2544 - val_loss: 775456803.9891\n",
      "Epoch 357/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 732756077.7291 - val_loss: 775002267.2809\n",
      "Epoch 358/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 732426635.6293 - val_loss: 774555881.1701\n",
      "Epoch 359/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 732105199.0341 - val_loss: 774122264.6323\n",
      "Epoch 360/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 731792931.2885 - val_loss: 773704260.9290\n",
      "Epoch 361/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 731489406.2944 - val_loss: 773286316.5229\n",
      "Epoch 362/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 731196984.6735 - val_loss: 772875561.5189\n",
      "Epoch 363/1000\n",
      "39624/39624 [==============================] - 1s 16us/sample - loss: 730907977.4844 - val_loss: 772492305.2872\n",
      "Epoch 364/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 730634146.3711 - val_loss: 772095702.8170\n",
      "Epoch 365/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 730362206.4559 - val_loss: 771726880.4296\n",
      "Epoch 366/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 730101285.9245 - val_loss: 771371388.5568\n",
      "Epoch 367/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 729851608.6412 - val_loss: 770994667.5539\n",
      "Epoch 368/1000\n",
      "39624/39624 [==============================] - 0s 13us/sample - loss: 729604111.2473 - val_loss: 770645876.5398\n",
      "Epoch 369/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 729367211.9071 - val_loss: 770310314.2166\n",
      "Epoch 370/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 729142148.2382 - val_loss: 769975110.1952\n",
      "Epoch 371/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 728922183.4040 - val_loss: 769653148.1530\n",
      "Epoch 372/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 728707630.9954 - val_loss: 769341849.3106\n",
      "Epoch 373/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 728504552.3408 - val_loss: 769031456.3908\n",
      "Epoch 374/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 728304955.5809 - val_loss: 768741610.8109\n",
      "Epoch 375/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 728114502.5641 - val_loss: 768465640.9698\n",
      "Epoch 376/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 727934570.8734 - val_loss: 768175865.9211\n",
      "Epoch 377/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 727753430.4963 - val_loss: 767903914.0616\n",
      "Epoch 378/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 727584390.8355 - val_loss: 767636791.4210\n",
      "Epoch 379/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 727419593.9237 - val_loss: 767386884.5544\n",
      "Epoch 380/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 727264020.2738 - val_loss: 767136698.8449\n",
      "Epoch 381/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 727112892.2915 - val_loss: 766897561.0780\n",
      "Epoch 382/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726968505.9528 - val_loss: 766667260.1821\n",
      "Epoch 383/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726832389.0394 - val_loss: 766428952.3093\n",
      "Epoch 384/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726697175.7496 - val_loss: 766216608.0937\n",
      "Epoch 385/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 726569566.3396 - val_loss: 766011547.1259\n",
      "Epoch 386/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726450126.8855 - val_loss: 765801267.0863\n",
      "Epoch 387/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726331484.9958 - val_loss: 765611219.3092\n",
      "Epoch 388/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726222239.7868 - val_loss: 765407255.1142\n",
      "Epoch 389/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726113650.4195 - val_loss: 765224684.2968\n",
      "Epoch 390/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 726012587.5195 - val_loss: 765048661.3829\n",
      "Epoch 391/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725916020.8875 - val_loss: 764868963.2203\n",
      "Epoch 392/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 725824142.4850 - val_loss: 764693777.1903\n",
      "Epoch 393/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725736009.2130 - val_loss: 764538473.3187\n",
      "Epoch 394/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725653751.1230 - val_loss: 764388470.3874\n",
      "Epoch 395/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725575681.8219 - val_loss: 764230410.2715\n",
      "Epoch 396/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725500296.7478 - val_loss: 764079237.8593\n",
      "Epoch 397/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725429547.0414 - val_loss: 763934894.1573\n",
      "Epoch 398/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725363116.0751 - val_loss: 763803584.0129\n",
      "Epoch 399/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725300930.8298 - val_loss: 763674467.2139\n",
      "Epoch 400/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725242586.7345 - val_loss: 763550083.4238\n",
      "Epoch 401/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 725186662.1183 - val_loss: 763436741.3425\n",
      "Epoch 402/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725135076.7745 - val_loss: 763318800.0210\n",
      "Epoch 403/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725085977.6103 - val_loss: 763210745.7337\n",
      "Epoch 404/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 725040580.0057 - val_loss: 763101852.7861\n",
      "Epoch 405/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724997367.5235 - val_loss: 763000002.9458\n",
      "Epoch 406/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724957564.4078 - val_loss: 762901170.5307\n",
      "Epoch 407/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724918749.1767 - val_loss: 762814329.1717\n",
      "Epoch 408/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724883967.8320 - val_loss: 762725063.5260\n",
      "Epoch 409/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724851761.0757 - val_loss: 762633683.9358\n",
      "Epoch 410/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724821254.9647 - val_loss: 762557225.3380\n",
      "Epoch 411/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724791420.9247 - val_loss: 762481585.9881\n",
      "Epoch 412/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724765151.0632 - val_loss: 762403785.3154\n",
      "Epoch 413/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724739872.7430 - val_loss: 762335140.1441\n",
      "Epoch 414/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724718978.5197 - val_loss: 762253143.5728\n",
      "Epoch 415/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724696133.6984 - val_loss: 762192630.7104\n",
      "Epoch 416/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724676184.9255 - val_loss: 762134046.2655\n",
      "Epoch 417/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724658735.8223 - val_loss: 762068658.9248\n",
      "Epoch 418/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724643306.2532 - val_loss: 762008026.7512\n",
      "Epoch 419/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724627329.3438 - val_loss: 761958809.6982\n",
      "Epoch 420/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724614122.7313 - val_loss: 761909755.6588\n",
      "Epoch 421/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724601893.0200 - val_loss: 761858174.8307\n",
      "Epoch 422/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724590300.4789 - val_loss: 761809156.6060\n",
      "Epoch 423/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724579382.9033 - val_loss: 761769224.4885\n",
      "Epoch 424/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724569601.3697 - val_loss: 761736346.9708\n",
      "Epoch 425/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724561301.4496 - val_loss: 761689255.4582\n",
      "Epoch 426/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724553243.2126 - val_loss: 761658535.0706\n",
      "Epoch 427/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724546238.2168 - val_loss: 761620072.8923\n",
      "Epoch 428/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724540063.6705 - val_loss: 761595994.8675\n",
      "Epoch 429/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724533515.4226 - val_loss: 761558629.8561\n",
      "Epoch 430/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724528280.2407 - val_loss: 761523515.2131\n",
      "Epoch 431/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724523565.6128 - val_loss: 761487603.1509\n",
      "Epoch 432/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724519340.5403 - val_loss: 761464937.8290\n",
      "Epoch 433/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724515648.1034 - val_loss: 761446516.1328\n",
      "Epoch 434/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724512521.2647 - val_loss: 761423720.8471\n",
      "Epoch 435/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724509390.8468 - val_loss: 761399970.4128\n",
      "Epoch 436/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724506973.8615 - val_loss: 761381226.1843\n",
      "Epoch 437/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724505453.8970 - val_loss: 761343972.4155\n",
      "Epoch 438/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724501987.9992 - val_loss: 761329606.8800\n",
      "Epoch 439/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724500149.7016 - val_loss: 761321605.1487\n",
      "Epoch 440/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724499409.7282 - val_loss: 761290379.2082\n",
      "Epoch 441/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724497675.3063 - val_loss: 761285475.5046\n",
      "Epoch 442/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724495469.2122 - val_loss: 761268738.2481\n",
      "Epoch 443/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724495457.0789 - val_loss: 761243342.7419\n",
      "Epoch 444/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493691.6584 - val_loss: 761236639.4670\n",
      "Epoch 445/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724493010.5552 - val_loss: 761229456.6153\n",
      "Epoch 446/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724492598.3477 - val_loss: 761229290.8174\n",
      "Epoch 447/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724491886.4397 - val_loss: 761213256.0686\n",
      "Epoch 448/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724491400.2697 - val_loss: 761211945.7192\n",
      "Epoch 449/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724491067.4904 - val_loss: 761187449.2880\n",
      "Epoch 450/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724489806.6659 - val_loss: 761183039.1020\n",
      "Epoch 451/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724490122.3372 - val_loss: 761183475.8357\n",
      "Epoch 452/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724490255.6996 - val_loss: 761157531.0160\n",
      "Epoch 453/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724489789.5191 - val_loss: 761157348.2087\n",
      "Epoch 454/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724491061.5078 - val_loss: 761172066.8004\n",
      "Epoch 455/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724489762.5132 - val_loss: 761147274.3620\n",
      "Epoch 456/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488757.9083 - val_loss: 761149162.1068\n",
      "Epoch 457/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724491093.4109 - val_loss: 761147719.7715\n",
      "Epoch 458/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724488379.7101 - val_loss: 761128559.7012\n",
      "Epoch 459/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724488106.7442 - val_loss: 761126669.6114\n",
      "Epoch 460/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487995.7101 - val_loss: 761127520.7655\n",
      "Epoch 461/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488812.9925 - val_loss: 761128962.9716\n",
      "Epoch 462/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488644.5225 - val_loss: 761113613.7858\n",
      "Epoch 463/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487728.6881 - val_loss: 761110921.8775\n",
      "Epoch 464/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488127.1859 - val_loss: 761111855.0811\n",
      "Epoch 465/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488230.0020 - val_loss: 761102797.8633\n",
      "Epoch 466/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488276.9328 - val_loss: 761110171.3261\n",
      "Epoch 467/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488092.1300 - val_loss: 761112147.0895\n",
      "Epoch 468/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488154.5148 - val_loss: 761102726.7895\n",
      "Epoch 469/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488241.9285 - val_loss: 761101527.3532\n",
      "Epoch 470/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488285.5514 - val_loss: 761100003.3366\n",
      "Epoch 471/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487552.0775 - val_loss: 761097911.7376\n",
      "Epoch 472/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488107.0802 - val_loss: 761095644.4373\n",
      "Epoch 473/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724488516.8455 - val_loss: 761091721.7999\n",
      "Epoch 474/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487721.5554 - val_loss: 761093176.6291\n",
      "Epoch 475/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724490167.4460 - val_loss: 761088352.5846\n",
      "Epoch 476/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487685.7242 - val_loss: 761096910.8323\n",
      "Epoch 477/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490555.1286 - val_loss: 761081155.7210\n",
      "Epoch 478/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488829.2607 - val_loss: 761103037.2674\n",
      "Epoch 479/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488504.3247 - val_loss: 761095516.9282\n",
      "Epoch 480/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489623.4395 - val_loss: 761077650.0495\n",
      "Epoch 481/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489285.1944 - val_loss: 761092066.1351\n",
      "Epoch 482/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488544.2132 - val_loss: 761095375.3168\n",
      "Epoch 483/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724490067.3693 - val_loss: 761076986.9353\n",
      "Epoch 484/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488372.9909 - val_loss: 761093475.1816\n",
      "Epoch 485/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488215.4395 - val_loss: 761090142.9309\n",
      "Epoch 486/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487612.4208 - val_loss: 761084182.7912\n",
      "Epoch 487/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488423.6430 - val_loss: 761080172.6004\n",
      "Epoch 488/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488563.5954 - val_loss: 761092641.1467\n",
      "Epoch 489/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490817.4084 - val_loss: 761090558.5077\n",
      "Epoch 490/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489507.6115 - val_loss: 761094566.8186\n",
      "Epoch 491/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488243.3887 - val_loss: 761074143.0213\n",
      "Epoch 492/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487889.5086 - val_loss: 761076617.3671\n",
      "Epoch 493/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487981.2510 - val_loss: 761086175.0342\n",
      "Epoch 494/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487504.7333 - val_loss: 761082844.1789\n",
      "Epoch 495/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487650.0093 - val_loss: 761081399.6859\n",
      "Epoch 496/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487943.7787 - val_loss: 761083194.5994\n",
      "Epoch 497/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489045.8114 - val_loss: 761085656.8132\n",
      "Epoch 498/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487566.1361 - val_loss: 761072907.3439\n",
      "Epoch 499/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487652.0250 - val_loss: 761072037.2811\n",
      "Epoch 500/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489547.7585 - val_loss: 761083797.3635\n",
      "Epoch 501/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487984.4167 - val_loss: 761067153.1644\n",
      "Epoch 502/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488744.1082 - val_loss: 761072014.9809\n",
      "Epoch 503/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487515.9104 - val_loss: 761075728.2342\n",
      "Epoch 504/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488268.4434 - val_loss: 761076345.1265\n",
      "Epoch 505/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487668.3965 - val_loss: 761073868.2031\n",
      "Epoch 506/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488306.7426 - val_loss: 761083754.0099\n",
      "Epoch 507/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489762.9784 - val_loss: 761090979.3754\n",
      "Epoch 508/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487709.4609 - val_loss: 761068319.0278\n",
      "Epoch 509/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488388.2770 - val_loss: 761076955.1776\n",
      "Epoch 510/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488965.3107 - val_loss: 761068009.2282\n",
      "Epoch 511/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488239.5639 - val_loss: 761070230.6943\n",
      "Epoch 512/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487744.3360 - val_loss: 761069888.8269\n",
      "Epoch 513/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489077.9729 - val_loss: 761076555.2276\n",
      "Epoch 514/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488574.9017 - val_loss: 761070984.1785\n",
      "Epoch 515/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488362.0723 - val_loss: 761073775.5656\n",
      "Epoch 516/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488619.4032 - val_loss: 761077408.3392\n",
      "Epoch 517/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489187.4048 - val_loss: 761079329.3728\n",
      "Epoch 518/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488155.9491 - val_loss: 761091069.4095\n",
      "Epoch 519/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488638.3202 - val_loss: 761084922.7609\n",
      "Epoch 520/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488934.8678 - val_loss: 761100391.4646\n",
      "Epoch 521/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487898.5794 - val_loss: 761084221.8100\n",
      "Epoch 522/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488441.5134 - val_loss: 761079192.5741\n",
      "Epoch 523/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488021.8243 - val_loss: 761084744.1009\n",
      "Epoch 524/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487956.1704 - val_loss: 761077011.0831\n",
      "Epoch 525/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487786.2015 - val_loss: 761078383.3588\n",
      "Epoch 526/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488945.6184 - val_loss: 761072825.2557\n",
      "Epoch 527/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487810.9073 - val_loss: 761076986.3087\n",
      "Epoch 528/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487711.4250 - val_loss: 761088099.3819\n",
      "Epoch 529/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487916.5274 - val_loss: 761081573.2036\n",
      "Epoch 530/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488723.9378 - val_loss: 761078494.1427\n",
      "Epoch 531/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488796.1042 - val_loss: 761079367.2934\n",
      "Epoch 532/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488088.2923 - val_loss: 761083424.9593\n",
      "Epoch 533/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724489782.3606 - val_loss: 761094272.8140\n",
      "Epoch 534/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490064.2164 - val_loss: 761069995.8769\n",
      "Epoch 535/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490993.8122 - val_loss: 761095165.0930\n",
      "Epoch 536/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489111.2069 - val_loss: 761075187.6935\n",
      "Epoch 537/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489418.7765 - val_loss: 761063866.9353\n",
      "Epoch 538/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487996.7826 - val_loss: 761067199.5930\n",
      "Epoch 539/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488221.5901 - val_loss: 761092610.1447\n",
      "Epoch 540/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488180.7454 - val_loss: 761093172.0553\n",
      "Epoch 541/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488090.0884 - val_loss: 761081883.6039\n",
      "Epoch 542/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488471.9176 - val_loss: 761088289.9865\n",
      "Epoch 543/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724490027.7004 - val_loss: 761078575.3524\n",
      "Epoch 544/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488130.7264 - val_loss: 761083245.2529\n",
      "Epoch 545/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724489331.3628 - val_loss: 761092841.5318\n",
      "Epoch 546/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488701.3640 - val_loss: 761074623.7222\n",
      "Epoch 547/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488167.2037 - val_loss: 761069727.8288\n",
      "Epoch 548/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488106.4599 - val_loss: 761089638.0886\n",
      "Epoch 549/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488758.4769 - val_loss: 761092547.0039\n",
      "Epoch 550/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493089.6087 - val_loss: 761055471.4105\n",
      "Epoch 551/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724491581.6095 - val_loss: 761096662.2356\n",
      "Epoch 552/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488135.3265 - val_loss: 761086959.8240\n",
      "Epoch 553/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488124.9505 - val_loss: 761089677.5145\n",
      "Epoch 554/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488684.3077 - val_loss: 761089981.6679\n",
      "Epoch 555/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488008.7220 - val_loss: 761095935.3411\n",
      "Epoch 556/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488094.5463 - val_loss: 761083842.4936\n",
      "Epoch 557/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724488216.0339 - val_loss: 761093996.7425\n",
      "Epoch 558/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488477.0087 - val_loss: 761092309.1955\n",
      "Epoch 559/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487881.3293 - val_loss: 761087558.3373\n",
      "Epoch 560/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487894.5738 - val_loss: 761086300.9864\n",
      "Epoch 561/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489173.3850 - val_loss: 761078267.7428\n",
      "Epoch 562/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489316.9295 - val_loss: 761096240.9028\n",
      "Epoch 563/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488123.6713 - val_loss: 761083048.4272\n",
      "Epoch 564/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488551.3200 - val_loss: 761075280.0404\n",
      "Epoch 565/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488250.4050 - val_loss: 761084185.5238\n",
      "Epoch 566/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488768.9820 - val_loss: 761081158.5893\n",
      "Epoch 567/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488054.7870 - val_loss: 761079755.0403\n",
      "Epoch 568/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488508.3432 - val_loss: 761102207.3540\n",
      "Epoch 569/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487583.1924 - val_loss: 761085902.5804\n",
      "Epoch 570/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487964.8019 - val_loss: 761084258.6389\n",
      "Epoch 571/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489136.5718 - val_loss: 761078624.4425\n",
      "Epoch 572/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489443.5857 - val_loss: 761081258.8885\n",
      "Epoch 573/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488618.7054 - val_loss: 761096687.8110\n",
      "Epoch 574/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489276.7309 - val_loss: 761100314.2861\n",
      "Epoch 575/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489426.0642 - val_loss: 761087509.6994\n",
      "Epoch 576/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488799.3475 - val_loss: 761100067.4271\n",
      "Epoch 577/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487932.2399 - val_loss: 761086823.7295\n",
      "Epoch 578/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488051.1690 - val_loss: 761098361.6820\n",
      "Epoch 579/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488711.7270 - val_loss: 761094373.0292\n",
      "Epoch 580/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487790.4010 - val_loss: 761092524.6198\n",
      "Epoch 581/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493975.4525 - val_loss: 761117090.5356\n",
      "Epoch 582/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488873.7363 - val_loss: 761096757.1664\n",
      "Epoch 583/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487519.3604 - val_loss: 761077902.9034\n",
      "Epoch 584/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488584.3473 - val_loss: 761092175.4073\n",
      "Epoch 585/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487765.8890 - val_loss: 761081357.8375\n",
      "Epoch 586/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489018.3146 - val_loss: 761074268.3274\n",
      "Epoch 587/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489079.5494 - val_loss: 761088410.6737\n",
      "Epoch 588/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488165.9633 - val_loss: 761086411.0209\n",
      "Epoch 589/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487709.9649 - val_loss: 761089574.1080\n",
      "Epoch 590/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487980.1009 - val_loss: 761086894.6482\n",
      "Epoch 591/1000\n",
      "39624/39624 [==============================] - 0s 13us/sample - loss: 724488989.6418 - val_loss: 761085696.2778\n",
      "Epoch 592/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488275.6535 - val_loss: 761084202.8497\n",
      "Epoch 593/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489124.0509 - val_loss: 761077105.1160\n",
      "Epoch 594/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488739.4953 - val_loss: 761083309.1624\n",
      "Epoch 595/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488256.2714 - val_loss: 761087475.1574\n",
      "Epoch 596/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487653.1750 - val_loss: 761085517.7212\n",
      "Epoch 597/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487974.2604 - val_loss: 761089639.0189\n",
      "Epoch 598/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488500.3448 - val_loss: 761106375.8813\n",
      "Epoch 599/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488699.7101 - val_loss: 761090104.5063\n",
      "Epoch 600/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489194.8605 - val_loss: 761088002.0285\n",
      "Epoch 601/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488236.6566 - val_loss: 761090433.9768\n",
      "Epoch 602/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488341.1395 - val_loss: 761095110.7508\n",
      "Epoch 603/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488289.4149 - val_loss: 761093080.8196\n",
      "Epoch 604/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487624.3214 - val_loss: 761086771.3189\n",
      "Epoch 605/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488392.7866 - val_loss: 761085745.2387\n",
      "Epoch 606/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487916.1656 - val_loss: 761091845.8722\n",
      "Epoch 607/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488611.4953 - val_loss: 761087515.0871\n",
      "Epoch 608/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488220.7503 - val_loss: 761090553.6304\n",
      "Epoch 609/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487496.4506 - val_loss: 761094883.0136\n",
      "Epoch 610/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488479.0374 - val_loss: 761095171.4497\n",
      "Epoch 611/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488396.5338 - val_loss: 761099043.9180\n",
      "Epoch 612/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488036.7486 - val_loss: 761099909.7689\n",
      "Epoch 613/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490291.1302 - val_loss: 761081125.4039\n",
      "Epoch 614/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488795.7682 - val_loss: 761092194.4451\n",
      "Epoch 615/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488904.6186 - val_loss: 761086241.7991\n",
      "Epoch 616/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488941.8841 - val_loss: 761094313.6933\n",
      "Epoch 617/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489448.5734 - val_loss: 761077656.6710\n",
      "Epoch 618/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488183.4201 - val_loss: 761090543.1973\n",
      "Epoch 619/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488619.3386 - val_loss: 761084401.0255\n",
      "Epoch 620/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488404.8294 - val_loss: 761072893.7261\n",
      "Epoch 621/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488287.3733 - val_loss: 761086459.5878\n",
      "Epoch 622/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488030.9340 - val_loss: 761073419.7186\n",
      "Epoch 623/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488475.5098 - val_loss: 761068403.2607\n",
      "Epoch 624/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488138.8540 - val_loss: 761069867.1727\n",
      "Epoch 625/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488195.8635 - val_loss: 761066413.3691\n",
      "Epoch 626/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489431.4395 - val_loss: 761081370.6930\n",
      "Epoch 627/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488109.8453 - val_loss: 761074501.0389\n",
      "Epoch 628/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489576.4700 - val_loss: 761085916.9799\n",
      "Epoch 629/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489026.4938 - val_loss: 761081386.3458\n",
      "Epoch 630/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487673.5263 - val_loss: 761078001.6392\n",
      "Epoch 631/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488022.2508 - val_loss: 761078784.9496\n",
      "Epoch 632/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488996.3739 - val_loss: 761075513.1459\n",
      "Epoch 633/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488063.0309 - val_loss: 761077108.3460\n",
      "Epoch 634/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487684.5225 - val_loss: 761080254.9599\n",
      "Epoch 635/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488427.7262 - val_loss: 761067863.4501\n",
      "Epoch 636/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488388.6259 - val_loss: 761075805.0122\n",
      "Epoch 637/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487495.8821 - val_loss: 761080460.5519\n",
      "Epoch 638/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488076.2108 - val_loss: 761078524.8023\n",
      "Epoch 639/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487699.6794 - val_loss: 761084500.3492\n",
      "Epoch 640/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488302.2201 - val_loss: 761088166.9155\n",
      "Epoch 641/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488484.3352 - val_loss: 761076047.6140\n",
      "Epoch 642/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487740.0590 - val_loss: 761086767.3330\n",
      "Epoch 643/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488001.4343 - val_loss: 761086438.2372\n",
      "Epoch 644/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489055.8643 - val_loss: 761074584.4320\n",
      "Epoch 645/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488045.8195 - val_loss: 761090156.8846\n",
      "Epoch 646/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490245.9051 - val_loss: 761095924.5269\n",
      "Epoch 647/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488207.4282 - val_loss: 761088280.4902\n",
      "Epoch 648/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488418.8879 - val_loss: 761090379.2987\n",
      "Epoch 649/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487830.9873 - val_loss: 761083118.9066\n",
      "Epoch 650/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488560.8948 - val_loss: 761088157.1673\n",
      "Epoch 651/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488055.9887 - val_loss: 761079980.4130\n",
      "Epoch 652/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487957.1912 - val_loss: 761092652.8717\n",
      "Epoch 653/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487840.6525 - val_loss: 761088938.2360\n",
      "Epoch 654/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487755.3321 - val_loss: 761088176.2826\n",
      "Epoch 655/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487492.4837 - val_loss: 761089222.6410\n",
      "Epoch 656/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488562.1482 - val_loss: 761088193.0465\n",
      "Epoch 657/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487910.2863 - val_loss: 761090960.9189\n",
      "Epoch 658/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488154.3985 - val_loss: 761088757.2504\n",
      "Epoch 659/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488168.3666 - val_loss: 761082852.7191\n",
      "Epoch 660/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488760.8803 - val_loss: 761067490.2513\n",
      "Epoch 661/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487781.0717 - val_loss: 761078261.6639\n",
      "Epoch 662/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488259.4759 - val_loss: 761080275.6451\n",
      "Epoch 663/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488926.7660 - val_loss: 761076390.1403\n",
      "Epoch 664/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488111.4735 - val_loss: 761078974.8630\n",
      "Epoch 665/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489434.9929 - val_loss: 761098574.1476\n",
      "Epoch 666/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489369.1839 - val_loss: 761098242.5711\n",
      "Epoch 667/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487454.7660 - val_loss: 761084341.7995\n",
      "Epoch 668/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488489.7622 - val_loss: 761094312.2528\n",
      "Epoch 669/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489014.8128 - val_loss: 761084823.8958\n",
      "Epoch 670/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488802.3840 - val_loss: 761077137.4358\n",
      "Epoch 671/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487993.2679 - val_loss: 761082657.6376\n",
      "Epoch 672/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487778.2031 - val_loss: 761089616.3892\n",
      "Epoch 673/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487982.3105 - val_loss: 761077036.4066\n",
      "Epoch 674/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488213.8631 - val_loss: 761091900.0335\n",
      "Epoch 675/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488305.1016 - val_loss: 761084017.0191\n",
      "Epoch 676/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488436.5774 - val_loss: 761090833.3001\n",
      "Epoch 677/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488419.6503 - val_loss: 761085554.4468\n",
      "Epoch 678/1000\n",
      "39624/39624 [==============================] - 0s 13us/sample - loss: 724488333.1670 - val_loss: 761082462.6789\n",
      "Epoch 679/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724489705.5167 - val_loss: 761093704.2043\n",
      "Epoch 680/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724487673.5393 - val_loss: 761083607.9346\n",
      "Epoch 681/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724488655.6996 - val_loss: 761086747.0096\n",
      "Epoch 682/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487675.5292 - val_loss: 761080947.0282\n",
      "Epoch 683/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490219.5970 - val_loss: 761061864.7760\n",
      "Epoch 684/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488567.5106 - val_loss: 761088150.4682\n",
      "Epoch 685/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489881.7912 - val_loss: 761074289.5488\n",
      "Epoch 686/1000\n",
      "39624/39624 [==============================] - 1s 15us/sample - loss: 724488735.0115 - val_loss: 761094230.9591\n",
      "Epoch 687/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488286.3784 - val_loss: 761083025.9073\n",
      "Epoch 688/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488118.5544 - val_loss: 761080910.4447\n",
      "Epoch 689/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488563.1948 - val_loss: 761093613.9247\n",
      "Epoch 690/1000\n",
      "39624/39624 [==============================] - 1s 14us/sample - loss: 724489017.7977 - val_loss: 761082023.4259\n",
      "Epoch 691/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489385.2453 - val_loss: 761091183.9661\n",
      "Epoch 692/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489766.8031 - val_loss: 761099883.3665\n",
      "Epoch 693/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487531.9588 - val_loss: 761083334.8671\n",
      "Epoch 694/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488161.8284 - val_loss: 761081186.3547\n",
      "Epoch 695/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487760.3069 - val_loss: 761087769.7047\n",
      "Epoch 696/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488300.7212 - val_loss: 761074754.8747\n",
      "Epoch 697/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488110.4785 - val_loss: 761094046.2978\n",
      "Epoch 698/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487881.4197 - val_loss: 761086832.0113\n",
      "Epoch 699/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488114.2128 - val_loss: 761078271.8837\n",
      "Epoch 700/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488676.8520 - val_loss: 761091307.5797\n",
      "Epoch 701/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487934.0359 - val_loss: 761088644.0375\n",
      "Epoch 702/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488190.7466 - val_loss: 761084992.5814\n",
      "Epoch 703/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487610.3275 - val_loss: 761086207.2571\n",
      "Epoch 704/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488463.6220 - val_loss: 761100023.8086\n",
      "Epoch 705/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487707.5486 - val_loss: 761084343.0657\n",
      "Epoch 706/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488071.6624 - val_loss: 761077712.3828\n",
      "Epoch 707/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489202.0836 - val_loss: 761094776.2027\n",
      "Epoch 708/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487897.7137 - val_loss: 761075647.3023\n",
      "Epoch 709/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489750.6126 - val_loss: 761083852.5584\n",
      "Epoch 710/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489174.4058 - val_loss: 761071583.8869\n",
      "Epoch 711/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487660.6824 - val_loss: 761078025.8581\n",
      "Epoch 712/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489277.2477 - val_loss: 761086833.7426\n",
      "Epoch 713/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489656.2342 - val_loss: 761092219.5878\n",
      "Epoch 714/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488620.3723 - val_loss: 761081263.0423\n",
      "Epoch 715/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489876.8811 - val_loss: 761062790.9704\n",
      "Epoch 716/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487911.4363 - val_loss: 761079375.7432\n",
      "Epoch 717/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724491642.3792 - val_loss: 761102641.9816\n",
      "Epoch 718/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488563.4791 - val_loss: 761084310.4682\n",
      "Epoch 719/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724491679.8256 - val_loss: 761090221.1301\n",
      "Epoch 720/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488691.1690 - val_loss: 761084998.0854\n",
      "Epoch 721/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488553.1807 - val_loss: 761081860.4962\n",
      "Epoch 722/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490384.4232 - val_loss: 761086900.4494\n",
      "Epoch 723/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488717.1282 - val_loss: 761081397.9223\n",
      "Epoch 724/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489322.1627 - val_loss: 761092574.5691\n",
      "Epoch 725/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488046.6982 - val_loss: 761087164.3888\n",
      "Epoch 726/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487848.1728 - val_loss: 761088341.4152\n",
      "Epoch 727/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487978.8734 - val_loss: 761081890.0188\n",
      "Epoch 728/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488609.8930 - val_loss: 761093343.3378\n",
      "Epoch 729/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488584.6186 - val_loss: 761080071.7004\n",
      "Epoch 730/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487519.9548 - val_loss: 761092645.1648\n",
      "Epoch 731/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488105.9043 - val_loss: 761091414.1193\n",
      "Epoch 732/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488000.8528 - val_loss: 761093848.1736\n",
      "Epoch 733/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488059.3224 - val_loss: 761089686.2808\n",
      "Epoch 734/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489204.9909 - val_loss: 761100178.6955\n",
      "Epoch 735/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488769.4343 - val_loss: 761082436.2055\n",
      "Epoch 736/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488278.2120 - val_loss: 761086041.4656\n",
      "Epoch 737/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488910.1748 - val_loss: 761103450.2085\n",
      "Epoch 738/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487867.6325 - val_loss: 761089321.3768\n",
      "Epoch 739/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489044.5193 - val_loss: 761096372.3266\n",
      "Epoch 740/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488095.2441 - val_loss: 761082128.3569\n",
      "Epoch 741/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488712.6961 - val_loss: 761086007.8732\n",
      "Epoch 742/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487970.7070 - val_loss: 761082893.0171\n",
      "Epoch 743/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487607.3426 - val_loss: 761090767.4848\n",
      "Epoch 744/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488112.8431 - val_loss: 761086912.7364\n",
      "Epoch 745/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487858.8330 - val_loss: 761085640.9084\n",
      "Epoch 746/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488821.4819 - val_loss: 761078134.1225\n",
      "Epoch 747/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488604.1946 - val_loss: 761084895.5898\n",
      "Epoch 748/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487446.8581 - val_loss: 761091562.9272\n",
      "Epoch 749/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489033.5231 - val_loss: 761088652.7587\n",
      "Epoch 750/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490312.6961 - val_loss: 761104803.7049\n",
      "Epoch 751/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487489.6023 - val_loss: 761091387.3552\n",
      "Epoch 752/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488008.0113 - val_loss: 761082501.7430\n",
      "Epoch 753/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488247.9629 - val_loss: 761078031.7109\n",
      "Epoch 754/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488406.7547 - val_loss: 761087940.7029\n",
      "Epoch 755/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488109.0571 - val_loss: 761086271.1666\n",
      "Epoch 756/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488824.6218 - val_loss: 761096113.0772\n",
      "Epoch 757/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488625.3212 - val_loss: 761087765.8544\n",
      "Epoch 758/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488893.5320 - val_loss: 761085211.0354\n",
      "Epoch 759/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488117.3140 - val_loss: 761078707.6160\n",
      "Epoch 760/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487508.8552 - val_loss: 761084667.8785\n",
      "Epoch 761/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488416.3166 - val_loss: 761085144.9876\n",
      "Epoch 762/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487987.8538 - val_loss: 761092133.1067\n",
      "Epoch 763/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487984.3909 - val_loss: 761085727.9580\n",
      "Epoch 764/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488682.4987 - val_loss: 761078247.2773\n",
      "Epoch 765/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488629.8696 - val_loss: 761074001.4228\n",
      "Epoch 766/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490700.0040 - val_loss: 761087525.2294\n",
      "Epoch 767/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488186.3662 - val_loss: 761080284.0626\n",
      "Epoch 768/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488518.3444 - val_loss: 761094540.2871\n",
      "Epoch 769/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490438.3961 - val_loss: 761077656.7356\n",
      "Epoch 770/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488906.8928 - val_loss: 761088097.0110\n",
      "Epoch 771/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488315.8910 - val_loss: 761091069.9199\n",
      "Epoch 772/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487730.3549 - val_loss: 761093698.9652\n",
      "Epoch 773/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487815.0422 - val_loss: 761087932.3436\n",
      "Epoch 774/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724493211.1868 - val_loss: 761096343.9798\n",
      "Epoch 775/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488240.5976 - val_loss: 761092060.3210\n",
      "Epoch 776/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490255.9322 - val_loss: 761100316.5406\n",
      "Epoch 777/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488010.4405 - val_loss: 761090739.7259\n",
      "Epoch 778/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724489532.4466 - val_loss: 761089199.8627\n",
      "Epoch 779/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489440.1098 - val_loss: 761101345.7281\n",
      "Epoch 780/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488045.7937 - val_loss: 761082095.7077\n",
      "Epoch 781/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488048.2875 - val_loss: 761086789.1487\n",
      "Epoch 782/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487965.3963 - val_loss: 761091525.5298\n",
      "Epoch 783/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488116.8746 - val_loss: 761089915.6847\n",
      "Epoch 784/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488900.8455 - val_loss: 761076270.9971\n",
      "Epoch 785/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488327.5720 - val_loss: 761087005.9102\n",
      "Epoch 786/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489972.5257 - val_loss: 761096628.8305\n",
      "Epoch 787/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493985.3115 - val_loss: 761062078.9341\n",
      "Epoch 788/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487668.4611 - val_loss: 761085083.0483\n",
      "Epoch 789/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488128.4652 - val_loss: 761087805.0607\n",
      "Epoch 790/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490809.3713 - val_loss: 761077123.9536\n",
      "Epoch 791/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487772.1300 - val_loss: 761077936.9932\n",
      "Epoch 792/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488320.7236 - val_loss: 761098036.8176\n",
      "Epoch 793/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488262.5124 - val_loss: 761086602.7044\n",
      "Epoch 794/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487573.8502 - val_loss: 761087034.1601\n",
      "Epoch 795/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487706.5407 - val_loss: 761088810.2683\n",
      "Epoch 796/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488723.3822 - val_loss: 761085050.8578\n",
      "Epoch 797/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488565.6370 - val_loss: 761094341.1358\n",
      "Epoch 798/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493569.3568 - val_loss: 761076433.8815\n",
      "Epoch 799/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487784.5346 - val_loss: 761096936.4789\n",
      "Epoch 800/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488152.5766 - val_loss: 761085440.7623\n",
      "Epoch 801/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488474.3598 - val_loss: 761088279.2304\n",
      "Epoch 802/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487794.3291 - val_loss: 761099091.6063\n",
      "Epoch 803/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488323.6955 - val_loss: 761092188.3339\n",
      "Epoch 804/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488302.7498 - val_loss: 761087909.0486\n",
      "Epoch 805/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488110.5560 - val_loss: 761089952.2487\n",
      "Epoch 806/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489132.5661 - val_loss: 761078566.7088\n",
      "Epoch 807/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488009.7428 - val_loss: 761094512.4183\n",
      "Epoch 808/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489136.2229 - val_loss: 761085546.4750\n",
      "Epoch 809/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488277.2687 - val_loss: 761097996.9718\n",
      "Epoch 810/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488320.1809 - val_loss: 761080768.9109\n",
      "Epoch 811/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487606.2055 - val_loss: 761085334.3971\n",
      "Epoch 812/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488610.9784 - val_loss: 761080665.2654\n",
      "Epoch 813/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487891.4726 - val_loss: 761087338.1262\n",
      "Epoch 814/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488056.4280 - val_loss: 761095376.0662\n",
      "Epoch 815/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487884.4563 - val_loss: 761085722.0923\n",
      "Epoch 816/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487569.3923 - val_loss: 761089601.3631\n",
      "Epoch 817/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489869.4125 - val_loss: 761098178.7197\n",
      "Epoch 818/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488656.4103 - val_loss: 761092868.2378\n",
      "Epoch 819/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487816.8512 - val_loss: 761088839.2870\n",
      "Epoch 820/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489515.0543 - val_loss: 761086256.3020\n",
      "Epoch 821/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488376.2600 - val_loss: 761093669.0809\n",
      "Epoch 822/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488808.5088 - val_loss: 761092290.7326\n",
      "Epoch 823/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487778.1514 - val_loss: 761083467.6604\n",
      "Epoch 824/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488237.7678 - val_loss: 761088659.8518\n",
      "Epoch 825/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487585.0531 - val_loss: 761081292.0933\n",
      "Epoch 826/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489107.7698 - val_loss: 761067397.2197\n",
      "Epoch 827/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488133.5433 - val_loss: 761074279.6390\n",
      "Epoch 828/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487941.4658 - val_loss: 761074174.9793\n",
      "Epoch 829/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488010.3372 - val_loss: 761069078.5263\n",
      "Epoch 830/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487602.7426 - val_loss: 761080163.2139\n",
      "Epoch 831/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488506.4179 - val_loss: 761087841.5924\n",
      "Epoch 832/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488557.6903 - val_loss: 761096758.5037\n",
      "Epoch 833/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487684.0703 - val_loss: 761080276.7756\n",
      "Epoch 834/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487787.9588 - val_loss: 761083550.1233\n",
      "Epoch 835/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487733.7404 - val_loss: 761078433.3082\n",
      "Epoch 836/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488352.6913 - val_loss: 761063651.3366\n",
      "Epoch 837/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488480.9885 - val_loss: 761079759.0197\n",
      "Epoch 838/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488727.2974 - val_loss: 761090751.1408\n",
      "Epoch 839/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487523.7408 - val_loss: 761083047.0770\n",
      "Epoch 840/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488604.4014 - val_loss: 761072837.8593\n",
      "Epoch 841/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487719.2296 - val_loss: 761078729.9356\n",
      "Epoch 842/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488984.2148 - val_loss: 761079533.3239\n",
      "Epoch 843/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489813.0232 - val_loss: 761093600.3715\n",
      "Epoch 844/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487683.2304 - val_loss: 761093858.2320\n",
      "Epoch 845/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487869.8550 - val_loss: 761098608.4248\n",
      "Epoch 846/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488640.9174 - val_loss: 761098013.2577\n",
      "Epoch 847/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487828.0153 - val_loss: 761089418.0648\n",
      "Epoch 848/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488032.7430 - val_loss: 761094250.7463\n",
      "Epoch 849/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489180.2592 - val_loss: 761095873.5310\n",
      "Epoch 850/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724490078.2104 - val_loss: 761083184.1340\n",
      "Epoch 851/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488521.2647 - val_loss: 761079881.7160\n",
      "Epoch 852/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488263.0293 - val_loss: 761080721.4939\n",
      "Epoch 853/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487738.8314 - val_loss: 761077864.0266\n",
      "Epoch 854/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724493136.9400 - val_loss: 761099252.9468\n",
      "Epoch 855/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490734.3493 - val_loss: 761058067.0960\n",
      "Epoch 856/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488486.1442 - val_loss: 761086254.3317\n",
      "Epoch 857/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487707.1221 - val_loss: 761080909.2496\n",
      "Epoch 858/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488047.2796 - val_loss: 761065921.6215\n",
      "Epoch 859/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488866.3840 - val_loss: 761072749.8149\n",
      "Epoch 860/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487997.4932 - val_loss: 761077158.7153\n",
      "Epoch 861/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488840.9546 - val_loss: 761069856.6622\n",
      "Epoch 862/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488559.1375 - val_loss: 761080510.3527\n",
      "Epoch 863/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487927.2780 - val_loss: 761080646.6474\n",
      "Epoch 864/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487693.5934 - val_loss: 761075913.5028\n",
      "Epoch 865/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487914.1369 - val_loss: 761083009.5698\n",
      "Epoch 866/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490550.4510 - val_loss: 761054817.9929\n",
      "Epoch 867/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487852.8892 - val_loss: 761072461.3336\n",
      "Epoch 868/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489861.5175 - val_loss: 761071295.2183\n",
      "Epoch 869/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488996.8262 - val_loss: 761089224.8568\n",
      "Epoch 870/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488355.8441 - val_loss: 761094032.8285\n",
      "Epoch 871/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487553.0208 - val_loss: 761085879.5244\n",
      "Epoch 872/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487551.5994 - val_loss: 761083397.6138\n",
      "Epoch 873/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488203.6293 - val_loss: 761089163.3956\n",
      "Epoch 874/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488565.0943 - val_loss: 761078248.9052\n",
      "Epoch 875/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488545.8672 - val_loss: 761091713.6861\n",
      "Epoch 876/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489629.5772 - val_loss: 761076799.7868\n",
      "Epoch 877/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487767.0131 - val_loss: 761080938.5461\n",
      "Epoch 878/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489659.3224 - val_loss: 761079893.0340\n",
      "Epoch 879/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488813.8453 - val_loss: 761077597.9425\n",
      "Epoch 880/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488460.4951 - val_loss: 761077336.0250\n",
      "Epoch 881/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488243.6600 - val_loss: 761079046.7702\n",
      "Epoch 882/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487776.7688 - val_loss: 761083461.5557\n",
      "Epoch 883/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489112.9126 - val_loss: 761093132.3000\n",
      "Epoch 884/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488307.3757 - val_loss: 761079422.1718\n",
      "Epoch 885/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488659.3951 - val_loss: 761093077.4539\n",
      "Epoch 886/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490663.5138 - val_loss: 761086279.0286\n",
      "Epoch 887/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488305.2695 - val_loss: 761091116.1999\n",
      "Epoch 888/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489374.1845 - val_loss: 761106096.6056\n",
      "Epoch 889/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487604.1381 - val_loss: 761089266.3886\n",
      "Epoch 890/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490742.0505 - val_loss: 761075712.8786\n",
      "Epoch 891/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487836.2722 - val_loss: 761094559.8869\n",
      "Epoch 892/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488246.0376 - val_loss: 761101158.5473\n",
      "Epoch 893/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488569.3454 - val_loss: 761098832.5507\n",
      "Epoch 894/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488546.8621 - val_loss: 761094394.7544\n",
      "Epoch 895/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488571.3612 - val_loss: 761083386.3474\n",
      "Epoch 896/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489140.7066 - val_loss: 761083246.9260\n",
      "Epoch 897/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487821.6451 - val_loss: 761083987.1025\n",
      "Epoch 898/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488073.0967 - val_loss: 761089569.9606\n",
      "Epoch 899/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488504.1696 - val_loss: 761096947.1057\n",
      "Epoch 900/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487924.9263 - val_loss: 761088581.5427\n",
      "Epoch 901/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488640.3230 - val_loss: 761101318.4988\n",
      "Epoch 902/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489392.5718 - val_loss: 761081894.2437\n",
      "Epoch 903/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488507.6067 - val_loss: 761091771.7363\n",
      "Epoch 904/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487977.2065 - val_loss: 761085923.0653\n",
      "Epoch 905/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488388.9748 - val_loss: 761079793.1870\n",
      "Epoch 906/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487809.5764 - val_loss: 761087176.7146\n",
      "Epoch 907/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724491334.4866 - val_loss: 761103309.5209\n",
      "Epoch 908/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488091.0575 - val_loss: 761090059.6217\n",
      "Epoch 909/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488014.3299 - val_loss: 761078003.4739\n",
      "Epoch 910/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488021.6305 - val_loss: 761081393.1935\n",
      "Epoch 911/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488239.3830 - val_loss: 761091510.0515\n",
      "Epoch 912/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489172.9715 - val_loss: 761094482.9668\n",
      "Epoch 913/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488098.4486 - val_loss: 761094898.3046\n",
      "Epoch 914/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487800.9578 - val_loss: 761091134.8436\n",
      "Epoch 915/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488311.7044 - val_loss: 761095630.1282\n",
      "Epoch 916/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488316.2011 - val_loss: 761091446.9171\n",
      "Epoch 917/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489292.5467 - val_loss: 761090302.1330\n",
      "Epoch 918/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488044.0363 - val_loss: 761081517.1689\n",
      "Epoch 919/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724490151.6947 - val_loss: 761088402.2110\n",
      "Epoch 920/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487267.9604 - val_loss: 761078631.5292\n",
      "Epoch 921/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489055.2053 - val_loss: 761080138.9628\n",
      "Epoch 922/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489500.5177 - val_loss: 761085558.7427\n",
      "Epoch 923/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489356.7406 - val_loss: 761071388.7797\n",
      "Epoch 924/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488362.3049 - val_loss: 761075155.9939\n",
      "Epoch 925/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488291.7537 - val_loss: 761082422.2517\n",
      "Epoch 926/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487762.5811 - val_loss: 761076361.6126\n",
      "Epoch 927/1000\n",
      "39624/39624 [==============================] - 1s 13us/sample - loss: 724487553.4472 - val_loss: 761079513.2524\n",
      "Epoch 928/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489583.8094 - val_loss: 761059826.1108\n",
      "Epoch 929/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488991.1278 - val_loss: 761088556.9169\n",
      "Epoch 930/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489255.5138 - val_loss: 761074138.4476\n",
      "Epoch 931/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487754.2209 - val_loss: 761080270.8711\n",
      "Epoch 932/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488271.4799 - val_loss: 761100374.1387\n",
      "Epoch 933/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487974.4284 - val_loss: 761096269.7406\n",
      "Epoch 934/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487940.8068 - val_loss: 761089946.4605\n",
      "Epoch 935/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488706.4551 - val_loss: 761092873.8129\n",
      "Epoch 936/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488896.1421 - val_loss: 761074936.9004\n",
      "Epoch 937/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488114.9622 - val_loss: 761096417.4309\n",
      "Epoch 938/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488909.2187 - val_loss: 761098666.9789\n",
      "Epoch 939/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488399.0277 - val_loss: 761083901.2092\n",
      "Epoch 940/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488252.7050 - val_loss: 761104613.9530\n",
      "Epoch 941/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488903.3006 - val_loss: 761084654.5255\n",
      "Epoch 942/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488503.0196 - val_loss: 761086780.2596\n",
      "Epoch 943/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489333.2106 - val_loss: 761104192.5103\n",
      "Epoch 944/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489525.7016 - val_loss: 761084374.1904\n",
      "Epoch 945/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724487796.4611 - val_loss: 761091196.3436\n",
      "Epoch 946/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488191.4056 - val_loss: 761091750.6507\n",
      "Epoch 947/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488244.1252 - val_loss: 761081882.3571\n",
      "Epoch 948/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488063.9742 - val_loss: 761082546.5630\n",
      "Epoch 949/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489356.0816 - val_loss: 761100114.9345\n",
      "Epoch 950/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489317.7436 - val_loss: 761079684.4898\n",
      "Epoch 951/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488266.5439 - val_loss: 761093425.4519\n",
      "Epoch 952/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487926.9291 - val_loss: 761093655.2692\n",
      "Epoch 953/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488515.9281 - val_loss: 761088514.6099\n",
      "Epoch 954/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488498.9364 - val_loss: 761097191.7747\n",
      "Epoch 955/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488201.1355 - val_loss: 761089408.3165\n",
      "Epoch 956/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488787.2917 - val_loss: 761080939.1081\n",
      "Epoch 957/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488245.4173 - val_loss: 761093818.1795\n",
      "Epoch 958/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488564.4353 - val_loss: 761090216.4530\n",
      "Epoch 959/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487757.8776 - val_loss: 761084161.5375\n",
      "Epoch 960/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488889.3584 - val_loss: 761077484.1482\n",
      "Epoch 961/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488453.3882 - val_loss: 761080242.7116\n",
      "Epoch 962/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488127.1859 - val_loss: 761080310.0256\n",
      "Epoch 963/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489585.7218 - val_loss: 761093104.2439\n",
      "Epoch 964/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487975.3459 - val_loss: 761095736.3319\n",
      "Epoch 965/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488736.8334 - val_loss: 761092116.0069\n",
      "Epoch 966/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488237.4706 - val_loss: 761109946.7738\n",
      "Epoch 967/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488155.7682 - val_loss: 761099575.4792\n",
      "Epoch 968/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488558.6465 - val_loss: 761103480.2414\n",
      "Epoch 969/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488452.1219 - val_loss: 761093515.2341\n",
      "Epoch 970/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488595.4080 - val_loss: 761086403.1719\n",
      "Epoch 971/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489014.5286 - val_loss: 761099090.1076\n",
      "Epoch 972/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489944.7575 - val_loss: 761108140.8136\n",
      "Epoch 973/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724492165.8276 - val_loss: 761083172.3250\n",
      "Epoch 974/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488417.1048 - val_loss: 761105840.3343\n",
      "Epoch 975/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488004.9748 - val_loss: 761105456.2762\n",
      "Epoch 976/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488131.8635 - val_loss: 761089569.1337\n",
      "Epoch 977/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488024.4603 - val_loss: 761087699.2058\n",
      "Epoch 978/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493711.9063 - val_loss: 761058795.9027\n",
      "Epoch 979/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488489.0127 - val_loss: 761082432.2907\n",
      "Epoch 980/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489261.2768 - val_loss: 761067405.0235\n",
      "Epoch 981/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488082.0125 - val_loss: 761077051.6459\n",
      "Epoch 982/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487871.3281 - val_loss: 761073100.0480\n",
      "Epoch 983/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488639.8320 - val_loss: 761083211.2664\n",
      "Epoch 984/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488622.0133 - val_loss: 761081239.8183\n",
      "Epoch 985/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724489880.5249 - val_loss: 761091433.8032\n",
      "Epoch 986/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488407.2069 - val_loss: 761082887.0479\n",
      "Epoch 987/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488502.9162 - val_loss: 761082083.5369\n",
      "Epoch 988/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488833.0466 - val_loss: 761095585.1402\n",
      "Epoch 989/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488547.4436 - val_loss: 761091451.2066\n",
      "Epoch 990/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488584.8254 - val_loss: 761086836.7401\n",
      "Epoch 991/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488180.9134 - val_loss: 761083674.6737\n",
      "Epoch 992/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487978.4987 - val_loss: 761084673.2274\n",
      "Epoch 993/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489221.3107 - val_loss: 761096781.7664\n",
      "Epoch 994/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724487888.2294 - val_loss: 761097402.6963\n",
      "Epoch 995/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724488504.3247 - val_loss: 761090634.9305\n",
      "Epoch 996/1000\n",
      "39624/39624 [==============================] - 0s 12us/sample - loss: 724493536.4070 - val_loss: 761113248.1647\n",
      "Epoch 997/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489584.5330 - val_loss: 761080383.6512\n",
      "Epoch 998/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489943.2586 - val_loss: 761094720.8527\n",
      "Epoch 999/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724488132.1995 - val_loss: 761082370.2998\n",
      "Epoch 1000/1000\n",
      "39624/39624 [==============================] - 0s 11us/sample - loss: 724489824.5362 - val_loss: 761067420.6052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed418da240>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.05)\n",
    "model.compile(optimizer=opt, loss=\"mse\")\n",
    "model.fit(x, y, validation_split=0.2, epochs=1000, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0d4a9-a05d-41dc-8649-c4d087320d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
